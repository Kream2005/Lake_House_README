# ğŸ­ Big Data Lakehouse - InduSense

## Mini-Projet Data Warehouse et Big Data Warehouse
**UniversitÃ© Sultan Moulay Slimane - ENSA Khouribga**  
**FiliÃ¨re: Informatique et IngÃ©nierie de DonnÃ©es (2Ã¨me annÃ©e)**  
**Module: Data Warehouse et Big Data Warehouse**  
**Professeur: M. Mostafa SAADI**

---

## ğŸ“‹ Description du Projet

Ce projet simule un environnement industriel IoT pour la sociÃ©tÃ© **InduSense**, qui opÃ¨re plusieurs sites Ã©quipÃ©s de capteurs collectant des mesures de tempÃ©rature, vibration et pression. Le systÃ¨me implÃ©mente une architecture **Data Lakehouse** basÃ©e sur **Apache Spark** et **Delta Lake**.

---

## ğŸ—ï¸ Architecture du Projet

```
projet_lakehouse/
â”œâ”€â”€ simulators/                    # Partie 1: Simulateurs de capteurs
â”‚   â”œâ”€â”€ temperature_sensor.py      # Simulateur tempÃ©rature
â”‚   â”œâ”€â”€ vibration_sensor.py        # Simulateur vibration
â”‚   â”œâ”€â”€ pressure_sensor.py         # Simulateur pression
â”‚   â””â”€â”€ fast_generator.py          # GÃ©nÃ©rateur rapide (tests)
â”‚
â”œâ”€â”€ pipeline/                      # Partie 2: Pipeline d'intÃ©gration
â”‚   â””â”€â”€ integration_pipeline.py    # Pipeline Spark + Delta Lake
â”‚
â”œâ”€â”€ analytics/                     # Partie 3: Analyses dÃ©cisionnelles
â”‚   â””â”€â”€ spark_analytics.py         # Analyses Spark SQL
â”‚
â”œâ”€â”€ data_lake/                     # Stockage des donnÃ©es
â”‚   â”œâ”€â”€ raw/                       # DonnÃ©es brutes (JSON)
â”‚   â”‚   â”œâ”€â”€ temperature/
â”‚   â”‚   â”œâ”€â”€ vibration/
â”‚   â”‚   â””â”€â”€ pressure/
â”‚   â”œâ”€â”€ warehouse/                 # Delta Lake (donnÃ©es transformÃ©es)
â”‚   â”œâ”€â”€ processed/                 # Fichiers traitÃ©s
â”‚   â””â”€â”€ checkpoints/               # Checkpoints streaming
â”‚
â”œâ”€â”€ reports/                       # Fichiers exportÃ©s pour Power BI
â”‚
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ GUIDE_POWERBI.md              # Instructions Power BI
â””â”€â”€ README.md                      # Ce fichier
```

---

## ğŸš€ Installation et Configuration

### PrÃ©requis
- Python 3.8+
- Java 8 ou 11 (pour Spark)
- Apache Spark 3.4+
- Power BI Desktop (pour la visualisation)

### Installation des dÃ©pendances

```bash
# CrÃ©er un environnement virtuel (optionnel mais recommandÃ©)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Configuration de Spark

Assurez-vous que les variables d'environnement sont configurÃ©es:
```bash
export SPARK_HOME=/path/to/spark
export PATH=$PATH:$SPARK_HOME/bin
export JAVA_HOME=/path/to/java
```

---

## ğŸ“– Guide d'Utilisation

### Partie 1: GÃ©nÃ©ration des DonnÃ©es

#### Option A: GÃ©nÃ©ration rapide (recommandÃ© pour les tests)
```bash
cd simulators
python fast_generator.py
```
GÃ©nÃ¨re 1000 mesures par type de capteur instantanÃ©ment.

#### Option B: Simulation en temps rÃ©el
```bash
# Terminal 1
python temperature_sensor.py

# Terminal 2
python vibration_sensor.py

# Terminal 3
python pressure_sensor.py
```
Chaque script gÃ©nÃ¨re des mesures toutes les 1-3 secondes.

### Partie 2: Pipeline d'IntÃ©gration

#### Mode Batch (traitement par lots)
```bash
cd pipeline
python integration_pipeline.py batch
```

#### Mode Streaming (surveillance continue)
```bash
python integration_pipeline.py streaming 120  # 120 secondes
```

### Partie 3: Analyses DÃ©cisionnelles

```bash
cd analytics
python spark_analytics.py
```

Les analyses produites:
1. **TempÃ©rature moyenne** par site et par machine
2. **Alertes critiques** par type de capteur
3. **Top 5 machines** avec la plus forte variabilitÃ© de vibration
4. **Ã‰volution horaire** de la pression par site

### Partie 4: Reporting Power BI

1. Les fichiers CSV sont exportÃ©s dans le dossier `reports/`
2. Suivre les instructions dans `GUIDE_POWERBI.md`
3. Importer les fichiers dans Power BI Desktop
4. CrÃ©er les visualisations selon le guide

---

## ğŸ“Š Structure des DonnÃ©es

### Format JSON des mesures

```json
{
  "sensor_id": "uuid-unique",
  "type": "temperature|vibration|pressure",
  "value": 45.67,
  "unit": "Celsius|mm/s|Bar",
  "site": "Site_Paris",
  "machine": "Machine_A1",
  "timestamp": "2026-01-08T10:30:00",
  "is_critical": false
}
```

### Seuils Critiques

| Type | Seuil Critique |
|------|----------------|
| TempÃ©rature | > 90Â°C |
| Vibration | > 10 mm/s |
| Pression | < 0.5 Bar ou > 10 Bar |

### Sites et Machines

- **Sites**: Site_Paris, Site_Lyon, Site_Marseille, Site_Toulouse, Site_Bordeaux
- **Machines**: Machine_A1, Machine_A2, Machine_B1, Machine_B2, Machine_C1

---

## ğŸ”§ Configuration Delta Lake

Le partitionnement des donnÃ©es dans le warehouse:
```
warehouse/
â”œâ”€â”€ temperature/
â”‚   â””â”€â”€ site=Site_Paris/
â”‚       â””â”€â”€ year=2026/
â”‚           â””â”€â”€ month=1/
â”‚               â””â”€â”€ day=8/
â”‚                   â””â”€â”€ *.parquet
```

---

## ğŸ“ˆ Analyses Spark SQL

### Exemple de requÃªte - TempÃ©rature moyenne
```sql
SELECT 
    site,
    machine,
    ROUND(AVG(value), 2) as temperature_moyenne,
    COUNT(*) as nombre_mesures,
    SUM(CASE WHEN is_critical THEN 1 ELSE 0 END) as alertes
FROM temperature
GROUP BY site, machine
ORDER BY site, machine
```

### Exemple de requÃªte - Top 5 variabilitÃ© vibration
```sql
SELECT 
    machine,
    site,
    ROUND(STDDEV(value), 3) as ecart_type,
    ROUND(AVG(value), 3) as moyenne
FROM vibration
GROUP BY machine, site
ORDER BY ecart_type DESC
LIMIT 5
```

---

## ğŸ¯ Livrables du Projet

- [x] **Partie 1**: 3 scripts simulateurs de capteurs
- [x] **Partie 2**: Pipeline d'intÃ©gration Spark + Delta Lake
- [x] **Partie 3**: Module d'analyses Spark SQL
- [x] **Partie 4**: Guide de crÃ©ation du tableau de bord Power BI
- [x] Documentation complÃ¨te

---

## ğŸ“ Notes Importantes

1. **Volume de donnÃ©es**: Minimum 1000 mesures par type (configurable)
2. **Delta Lake**: Format de stockage optimisÃ© avec support ACID
3. **Partitionnement**: Par site, annÃ©e, mois, jour pour performances optimales
4. **Power BI**: Utiliser les fichiers CSV exportÃ©s pour l'import

---

## ğŸ› DÃ©pannage

### Erreur Java non trouvÃ©
```bash
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```

### Erreur mÃ©moire Spark
Augmenter la mÃ©moire dans le script:
```python
.config("spark.driver.memory", "4g")
```

### Fichiers Delta corrompus
Supprimer le dossier `warehouse/` et relancer le pipeline.

---

## ğŸ‘¥ Auteur

Projet rÃ©alisÃ© dans le cadre du module Data Warehouse et Big Data Warehouse.

---

## ğŸ“„ Licence

Projet acadÃ©mique - ENSA Khouribga 2025-2026
